{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "import data_related as data\n",
    "import bpe\n",
    "import utils\n",
    "import pretrained_model as pm\n",
    "import data_loader as dl\n",
    "import trainer\n",
    "import initializer as init\n",
    "import tester\n",
    "import model_util as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg length / 5: 7\n"
     ]
    }
   ],
   "source": [
    "first_np, second_np, label_np  = data.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearized complete!\n"
     ]
    }
   ],
   "source": [
    "first_np, second_np = utils.process_splitted(first_np, second_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done tokenizing both data!\n",
      "saved ch2idx to file!\n",
      "encoding comlete!\n"
     ]
    }
   ],
   "source": [
    "first_ls, second_ls, ch2idx, max_len = utils.tokenize(first_np, second_np, '/relation/ch2idx_relation')\n",
    "first2idx_np, second2idx_np = utils.encode(first_ls, second_ls, ch2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_word2vec = pm.load_pretrained_model(ch2idx)\n",
    "# pretrained_word2vec = torch.tensor(pretrained_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_first, test_first, train_second, test_second, train_labels, test_labels = train_test_split(\n",
    "    first2idx_np, second2idx_np, label_np, test_size = 0.1, random_state = 43\n",
    ")\n",
    "\n",
    "train_first, val_first, train_second, val_second, train_labels, val_labels = train_test_split(\n",
    "    train_first, train_second, train_labels, test_size = 0.1, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = dl.data_loader(\n",
    "                                                                   train_first,\n",
    "                                                                   train_second,\n",
    "                                                                   val_first,\n",
    "                                                                   val_second,\n",
    "                                                                   test_first,\n",
    "                                                                   test_second,\n",
    "                                                                   train_labels,\n",
    "                                                                   val_labels,\n",
    "                                                                   test_labels,\n",
    "                                                                   batch_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorBoard support\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/final/related')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = 'related_dc_1'\n",
    "epochs = 40\n",
    "\n",
    "input_size=len(ch2idx)\n",
    "embed_dim = 300\n",
    "hidden_size = 800\n",
    "num_classes = 2\n",
    "rnn_layers = 1\n",
    "\n",
    "num_filters = [100, 200, 100]\n",
    "kernel_sizes = [15, 21, 114]\n",
    "\n",
    "dropout = 0.0\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model_name=\"RNN\"\n",
    "optim_name=\"Adam\"\n",
    "loss_fn_name=\"CEL\"\n",
    "\n",
    "pretrained_model=None\n",
    "freeze_embedding=False,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing without pretrained model!!!\n",
      "OCR_rnn(\n",
      "  (emb): Embedding(115, 300)\n",
      "  (lstm1): RNN(\n",
      "    (rnn): LSTM(300, 800, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (lstm2): RNN(\n",
      "    (rnn): LSTM(300, 800, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=3200, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=2, bias=True)\n",
      "  (dp1): Dropout(p=0.0, inplace=False)\n",
      "  (dp2): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "model, optimizer, loss_fn = init.initialize_model(\n",
    "    vocab_size=input_size,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_classes=num_classes,\n",
    "    rnn_layers=rnn_layers,\n",
    "    num_filters=num_filters,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    dropout=dropout,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    model_name=model_name,\n",
    "    optim_name=optim_name,\n",
    "    loss_fn_name=loss_fn_name,\n",
    "    pretrained_model=pretrained_model,\n",
    "    freeze_embedding=freeze_embedding,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   0.583478   | 67.691358  | 0.545200 | 71.49  | 28.35 \n",
      "   2    |   0.517060   | 73.616049  | 0.511744 | 74.01  | 28.46 \n",
      "   3    |   0.487426   | 75.919753  | 0.484632 | 76.27  | 28.53 \n",
      "   4    |   0.468273   | 77.285185  | 0.476431 | 76.73  | 28.48 \n",
      "   5    |   0.454305   | 78.274074  | 0.466840 | 77.74  | 28.26 \n",
      "   6    |   0.442094   | 79.030864  | 0.462211 | 77.73  | 28.70 \n",
      "   7    |   0.431807   | 79.807407  | 0.451096 | 79.04  | 28.78 \n",
      "   8    |   0.421830   | 80.323457  | 0.455139 | 78.31  | 28.84 \n",
      "   9    |   0.412423   | 80.859259  | 0.443124 | 78.91  | 28.99 \n",
      "  10    |   0.404210   | 81.345679  | 0.436390 | 79.62  | 28.98 \n",
      "  11    |   0.396488   | 81.902469  | 0.446279 | 78.72  | 28.94 \n",
      "  12    |   0.388305   | 82.339506  | 0.447480 | 78.52  | 29.28 \n",
      "  13    |   0.382847   | 82.681481  | 0.435802 | 79.44  | 29.19 \n",
      "  14    |   0.374130   | 83.219753  | 0.433300 | 79.92  | 29.29 \n",
      "  15    |   0.367470   | 83.518519  | 0.440495 | 79.46  | 29.34 \n",
      "  16    |   0.361173   | 83.907407  | 0.431405 | 80.26  | 28.44 \n",
      "  17    |   0.354532   | 84.250617  | 0.434998 | 79.97  | 28.49 \n",
      "  18    |   0.348469   | 84.534568  | 0.435720 | 80.14  | 29.27 \n",
      "  19    |   0.340728   | 85.062963  | 0.438345 | 79.90  | 29.29 \n",
      "  20    |   0.332981   | 85.377778  | 0.444946 | 79.76  | 29.28 \n",
      "  21    |   0.326077   | 85.706173  | 0.442588 | 79.82  | 29.23 \n",
      "  22    |   0.318370   | 86.198765  | 0.446773 | 79.86  | 29.28 \n",
      "  23    |   0.311840   | 86.481481  | 0.445709 | 80.16  | 28.89 \n",
      "  24    |   0.304300   | 86.843210  | 0.446392 | 79.96  | 28.87 \n",
      "  25    |   0.297868   | 87.201235  | 0.453899 | 80.61  | 28.91 \n",
      "  26    |   0.290301   | 87.635802  | 0.459261 | 79.80  | 29.14 \n",
      "  27    |   0.284548   | 87.717284  | 0.466006 | 80.13  | 28.73 \n",
      "  28    |   0.276554   | 88.165432  | 0.469470 | 79.83  | 28.73 \n",
      "  29    |   0.269162   | 88.681481  | 0.474352 | 80.04  | 28.53 \n",
      "  30    |   0.262881   | 89.002469  | 0.480322 | 80.32  | 28.40 \n",
      "  31    |   0.253523   | 89.448148  | 0.485766 | 80.08  | 28.49 \n",
      "  32    |   0.249544   | 89.503704  | 0.496456 | 79.23  | 28.20 \n",
      "  33    |   0.242355   | 89.945679  | 0.501353 | 79.34  | 28.39 \n",
      "  34    |   0.234524   | 90.223457  | 0.516090 | 78.73  | 28.41 \n",
      "  35    |   0.228178   | 90.486420  | 0.511777 | 79.70  | 28.70 \n",
      "  36    |   0.223104   | 90.798765  | 0.530474 | 79.18  | 28.74 \n",
      "  37    |   0.215625   | 91.166667  | 0.548478 | 79.26  | 28.88 \n",
      "  38    |   0.211010   | 91.364198  | 0.532843 | 79.42  | 28.98 \n",
      "  39    |   0.203769   | 91.727160  | 0.550435 | 79.23  | 29.10 \n",
      "  40    |   0.195319   | 92.124691  | 0.562625 | 78.99  | 28.83 \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 80.61%.\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(title, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR_rnn(\n",
      "  (emb): Embedding(115, 300)\n",
      "  (lstm1): RNN(\n",
      "    (rnn): LSTM(300, 800, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (lstm2): RNN(\n",
      "    (rnn): LSTM(300, 800, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=3200, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=2, bias=True)\n",
      "  (dp1): Dropout(p=0.0, inplace=False)\n",
      "  (dp2): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mu.getModel(title)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.5759917970746755\n",
      "test acc:  78.75\n",
      "saved precision and recall results to file!\n"
     ]
    }
   ],
   "source": [
    "loss, acc = tester.test(test_dataloader=test_dataloader,\n",
    "                        device=device,\n",
    "                        model=model,\n",
    "                        title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../result/final_related', 'a') as f:\n",
    "        text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(end_time, 3)) + ' min\\n'\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded model graph to tensorboard!\n"
     ]
    }
   ],
   "source": [
    "mu.graphModel(train_dataloader, model, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
