{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 := delete \\n\n",
    "# 1 := leave as it is\n",
    "\n",
    "# model = gensim.models.Word2Vec.load('../../../pretrained_model/kor/ko.bin')\n",
    "\n",
    "# from hangul_utils import split_syllables, join_jamos\n",
    "# import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import data\n",
    "import bpe\n",
    "import utils\n",
    "import pretrained_model as pm\n",
    "import data_loader as dl\n",
    "import trainer\n",
    "import initializer as init\n",
    "import tester\n",
    "import model_util as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearized complete!\n",
      "done tokenizing both data!\n",
      "saved ch2idx to file!\n",
      "encoding comlete!\n"
     ]
    }
   ],
   "source": [
    "first_np, second_np, label_np  = data.getData()\n",
    "first_np, second_np = utils.process_splitted(first_np, second_np)\n",
    "first_ls, second_ls, ch2idx, max_len = utils.tokenize(first_np, second_np)\n",
    "first2idx_np, second2idx_np = utils.encode(first_ls, second_ls, ch2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27 / 133 pretrained vectors found.\n"
     ]
    }
   ],
   "source": [
    "pretrained_word2vec = pm.load_pretrained_model(ch2idx)\n",
    "pretrained_word2vec = torch.tensor(pretrained_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_first, test_first, train_second, test_second, train_labels, test_labels = train_test_split(\n",
    "    first2idx_np, second2idx_np, label_np, test_size = 0.1, random_state = 43\n",
    ")\n",
    "\n",
    "train_first, val_first, train_second, val_second, train_labels, val_labels = train_test_split(\n",
    "    train_first, train_second, train_labels, test_size = 0.1, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = dl.data_loader(train_first,\n",
    "                                                                   train_second,\n",
    "                                                                   val_first,\n",
    "                                                                   val_second,\n",
    "                                                                   test_first,\n",
    "                                                                   test_second,\n",
    "                                                                   train_labels,\n",
    "                                                                   val_labels,\n",
    "                                                                   test_labels,\n",
    "                                                                   batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "# PyTorch TensorBoard support\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('cnn-ocr/tests')\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = 'cnn-test10'\n",
    "epochs = 40\n",
    "\n",
    "vocab_size=len(ch2idx)\n",
    "embed_dim = 200\n",
    "hidden_size = 100\n",
    "num_classes = 2\n",
    "rnn_layers = 1\n",
    "\n",
    "num_filters = [100, 200, 100]\n",
    "kernel_sizes = [15, 21, 14]\n",
    "\n",
    "dropout = 0.2\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model_name=\"CNN\"\n",
    "optim_name=\"Adam\"\n",
    "loss_fn_name=\"CEL\"\n",
    "\n",
    "pretrained_model=pretrained_word2vec\n",
    "freeze_embedding=False,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing with pretrained model!!!\n",
      "OCR_cnn(\n",
      "  (emb): Embedding(133, 200)\n",
      "  (cnn1): CNN(\n",
      "    (conv1d_list): ModuleList(\n",
      "      (0): Conv1d(200, 100, kernel_size=(15,), stride=(1,))\n",
      "      (1): Conv1d(200, 200, kernel_size=(21,), stride=(1,))\n",
      "      (2): Conv1d(200, 100, kernel_size=(14,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (cnn2): CNN(\n",
      "    (conv1d_list): ModuleList(\n",
      "      (0): Conv1d(200, 100, kernel_size=(15,), stride=(1,))\n",
      "      (1): Conv1d(200, 200, kernel_size=(21,), stride=(1,))\n",
      "      (2): Conv1d(200, 100, kernel_size=(14,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=800, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=2, bias=True)\n",
      "  (dp1): Dropout(p=0.2, inplace=False)\n",
      "  (dp2): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "model, optimizer, loss_fn = init.initialize_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_classes=num_classes,\n",
    "    rnn_layers=rnn_layers,\n",
    "    num_filters=num_filters,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    dropout=dropout,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    model_name=model_name,\n",
    "    optim_name=optim_name,\n",
    "    loss_fn_name=loss_fn_name,\n",
    "    pretrained_model=pretrained_model,\n",
    "    freeze_embedding=freeze_embedding,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   0.524505   | 72.444444  | 0.356814 | 83.15  | 20.37 \n",
      "   2    |   0.367531   | 82.432099  | 0.292793 | 86.67  | 20.18 \n",
      "   3    |   0.326544   | 84.510288  | 0.316835 | 86.70  | 20.24 \n",
      "   4    |   0.312314   | 85.518519  | 0.272748 | 87.81  | 20.31 \n",
      "   5    |   0.287882   | 86.864198  | 0.257756 | 89.41  | 20.14 \n",
      "   6    |   0.272846   | 87.748971  | 0.251782 | 88.89  | 20.26 \n",
      "   7    |   0.263317   | 88.172840  | 0.272955 | 87.48  | 19.98 \n",
      "   8    |   0.248802   | 89.230453  | 0.248158 | 89.96  | 20.21 \n",
      "   9    |   0.243757   | 89.477366  | 0.255687 | 88.44  | 19.97 \n",
      "  10    |   0.238547   | 89.711934  | 0.243835 | 90.19  | 19.81 \n",
      "  11    |   0.226808   | 90.366255  | 0.226069 | 90.52  | 20.12 \n",
      "  12    |   0.223545   | 90.489712  | 0.221298 | 90.70  | 19.86 \n",
      "  13    |   0.212955   | 90.958848  | 0.254848 | 89.74  | 19.85 \n",
      "  14    |   0.213337   | 91.037037  | 0.262255 | 88.56  | 19.83 \n",
      "  15    |   0.203298   | 91.288066  | 0.225899 | 91.00  | 19.82 \n",
      "  16    |   0.197837   | 91.814815  | 0.229044 | 91.41  | 19.84 \n",
      "  17    |   0.197451   | 91.687243  | 0.232600 | 90.52  | 19.82 \n",
      "  18    |   0.190515   | 91.839506  | 0.224233 | 91.44  | 19.86 \n",
      "  19    |   0.188969   | 92.127572  | 0.209162 | 92.33  | 19.84 \n",
      "  20    |   0.187532   | 92.382716  | 0.208355 | 91.70  | 19.90 \n",
      "  21    |   0.183975   | 92.473251  | 0.200648 | 92.26  | 19.97 \n",
      "  22    |   0.178776   | 92.683128  | 0.213425 | 91.78  | 19.99 \n",
      "  23    |   0.176887   | 92.641975  | 0.243116 | 90.44  | 20.20 \n",
      "  24    |   0.182207   | 92.390947  | 0.216841 | 92.37  | 20.11 \n",
      "  25    |   0.179747   | 92.555556  | 0.194081 | 92.67  | 20.09 \n",
      "  26    |   0.174760   | 92.884774  | 0.213563 | 91.96  | 20.04 \n",
      "  27    |   0.175566   | 92.884774  | 0.242485 | 89.74  | 20.12 \n",
      "  28    |   0.172235   | 92.946502  | 0.207825 | 92.26  | 20.28 \n",
      "  29    |   0.171458   | 93.152263  | 0.222492 | 91.26  | 20.30 \n",
      "  30    |   0.174669   | 92.868313  | 0.193631 | 93.22  | 20.21 \n",
      "  31    |   0.163856   | 93.308642  | 0.211523 | 91.78  | 20.27 \n",
      "  32    |   0.163602   | 93.465021  | 0.216765 | 91.59  | 20.14 \n",
      "  33    |   0.169583   | 93.020576  | 0.220941 | 91.63  | 20.19 \n",
      "  34    |   0.164218   | 93.580247  | 0.216439 | 91.59  | 20.30 \n",
      "  35    |   0.164338   | 93.444444  | 0.208943 | 91.67  | 20.33 \n",
      "  36    |   0.169067   | 93.090535  | 0.202815 | 92.70  | 20.36 \n",
      "  37    |   0.168703   | 93.152263  | 0.214640 | 91.93  | 20.33 \n",
      "  38    |   0.164399   | 93.403292  | 0.208023 | 92.44  | 20.27 \n",
      "  39    |   0.161347   | 93.386831  | 0.221126 | 92.19  | 20.15 \n",
      "  40    |   0.161016   | 93.378601  | 0.195206 | 93.15  | 20.20 \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 93.22%.\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.1744551310315728\n",
      "test acc:  93.53333333333333\n",
      "saved precision and recall results to file!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'),\n",
       " tensor([1., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.test(test_dataloader=test_dataloader,\n",
    "            device=device,\n",
    "            model=model,\n",
    "            title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu.graphModel(train_dataloader, model, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(title, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
