{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 := delete \\n\n",
    "# 1 := leave as it is\n",
    "\n",
    "# model = gensim.models.Word2Vec.load('../../../pretrained_model/kor/ko.bin')\n",
    "\n",
    "# from hangul_utils import split_syllables, join_jamos\n",
    "# import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import data\n",
    "import bpe\n",
    "import utils\n",
    "import pretrained_model as pm\n",
    "import data_loader as dl\n",
    "import trainer\n",
    "import initializer as init\n",
    "import tester\n",
    "import model_util as mu\n",
    "# import predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data.getInitData()\n",
    "# data.mk_initData(df)\n",
    "# first_np, second_np, label_np = utils.process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearized complete!\n",
      "done tokenizing both data!\n",
      "saved ch2idx to file!\n",
      "encoding comlete!\n"
     ]
    }
   ],
   "source": [
    "first_np, second_np, label_np  = data.getData()\n",
    "first_np, second_np = utils.process_splitted(first_np, second_np)\n",
    "first_ls, second_ls, ch2idx, max_len = utils.tokenize(first_np, second_np)\n",
    "first2idx_np, second2idx_np = utils.encode(first_ls, second_ls, ch2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27 / 133 pretrained vectors found.\n"
     ]
    }
   ],
   "source": [
    "pretrained_word2vec = pm.load_pretrained_model(ch2idx)\n",
    "pretrained_word2vec = torch.tensor(pretrained_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_first, test_first, train_second, test_second, train_labels, test_labels = train_test_split(\n",
    "    first2idx_np, second2idx_np, label_np, test_size = 0.1, random_state = 43\n",
    ")\n",
    "\n",
    "train_first, val_first, train_second, val_second, train_labels, val_labels = train_test_split(\n",
    "    train_first, train_second, train_labels, test_size = 0.1, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = dl.data_loader(train_first,\n",
    "                                                                   train_second,\n",
    "                                                                   val_first,\n",
    "                                                                   val_second,\n",
    "                                                                   test_first,\n",
    "                                                                   test_second,\n",
    "                                                                   train_labels,\n",
    "                                                                   val_labels,\n",
    "                                                                   test_labels,\n",
    "                                                                   batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "# PyTorch TensorBoard support\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('ocr/tests')\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = 'test8'\n",
    "epochs = 40\n",
    "\n",
    "vocab_size=len(ch2idx)\n",
    "embed_dim = 200\n",
    "hidden_size = 100\n",
    "num_classes = 2\n",
    "rnn_layers = 2\n",
    "dropout = 0\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model_name=\"RNN\"\n",
    "optim_name=\"Adam\"\n",
    "loss_fn_name=\"CEL\"\n",
    "\n",
    "pretrained_model=pretrained_word2vec\n",
    "freeze_embedding=False,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing with pretrained model!!!\n",
      "OCR(\n",
      "  (emb): Embedding(133, 200)\n",
      "  (lstm1): RNN(\n",
      "    (rnn): LSTM(200, 100, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (lstm2): RNN(\n",
      "    (rnn): LSTM(200, 100, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=2, bias=True)\n",
      "  (dp1): Dropout(p=0, inplace=False)\n",
      "  (dp2): Dropout(p=0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "model, optimizer, loss_fn = init.initialize_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_classes=num_classes,\n",
    "    rnn_layers=rnn_layers,\n",
    "    dropout=dropout,\n",
    "    learning_rate=learning_rate,\n",
    "    model_name=model_name,\n",
    "    optim_name=optim_name,\n",
    "    loss_fn_name=loss_fn_name,\n",
    "    pretrained_model=pretrained_model,\n",
    "    freeze_embedding=freeze_embedding,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   0.353228   | 85.580247  | 0.197958 | 92.89  | 110.53\n",
      "   2    |   0.203694   | 92.362140  | 0.193038 | 93.15  | 110.55\n",
      "   3    |   0.183011   | 93.094650  | 0.184187 | 93.52  | 111.05\n",
      "   4    |   0.172904   | 93.526749  | 0.157986 | 94.37  | 110.53\n",
      "   5    |   0.167464   | 93.658436  | 0.156329 | 94.59  | 110.29\n",
      "   6    |   0.161556   | 93.983539  | 0.144652 | 94.93  | 110.31\n",
      "   7    |   0.154053   | 94.160494  | 0.147679 | 94.63  | 110.56\n",
      "   8    |   0.148616   | 94.427984  | 0.139565 | 95.11  | 110.39\n",
      "   9    |   0.148013   | 94.510288  | 0.140064 | 95.37  | 110.59\n",
      "  10    |   0.151010   | 94.477366  | 0.145625 | 94.70  | 110.50\n",
      "  11    |   0.141698   | 94.818930  | 0.139856 | 95.04  | 111.29\n",
      "  12    |   0.137964   | 94.888889  | 0.132243 | 95.22  | 110.54\n",
      "  13    |   0.132628   | 95.074074  | 0.136343 | 95.56  | 110.02\n",
      "  14    |   0.129683   | 95.164609  | 0.133984 | 95.56  | 109.79\n",
      "  15    |   0.126995   | 95.234568  | 0.141950 | 94.63  | 109.74\n",
      "  16    |   0.125011   | 95.419753  | 0.133923 | 95.15  | 110.26\n",
      "  17    |   0.123244   | 95.403292  | 0.127317 | 95.56  | 110.73\n",
      "  18    |   0.123843   | 95.518519  | 0.134461 | 95.11  | 110.74\n",
      "  19    |   0.119134   | 95.666667  | 0.126115 | 95.56  | 110.42\n",
      "  20    |   0.114945   | 95.876543  | 0.127367 | 95.56  | 109.78\n",
      "  21    |   0.110949   | 95.876543  | 0.139992 | 95.37  | 109.89\n",
      "  22    |   0.112465   | 95.855967  | 0.124383 | 95.59  | 109.53\n",
      "  23    |   0.107596   | 96.168724  | 0.121723 | 95.81  | 110.00\n",
      "  24    |   0.104563   | 96.259259  | 0.129681 | 95.74  | 110.42\n",
      "  25    |   0.106264   | 96.156379  | 0.131415 | 95.59  | 110.75\n",
      "  26    |   0.100062   | 96.386831  | 0.141978 | 95.22  | 111.29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/arise/auto/ocr/src/main.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     title\u001b[39m=\u001b[39;49mtitle,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     writer\u001b[39m=\u001b[39;49mwriter,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     val_dataloader\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mloss_fn\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arise/auto/ocr/src/main.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "File \u001b[0;32m~/auto/ocr/src/trainer.py:57\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, title, writer, train_dataloader, val_dataloader, device, model, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     54\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     56\u001b[0m \u001b[39m# Perform a forward pass. This will return logits.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m logits \u001b[39m=\u001b[39m model(firsts, seconds)\n\u001b[1;32m     59\u001b[0m \u001b[39m# Compute loss and accumulate the loss values\u001b[39;00m\n\u001b[1;32m     60\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, labels)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/auto/ocr/src/ocr_model.py:111\u001b[0m, in \u001b[0;36mOCR.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    108\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb(x2)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    110\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm1(a)\n\u001b[0;32m--> 111\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm2(b)\n\u001b[1;32m    113\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((a, b), \u001b[39m1\u001b[39m)\n\u001b[1;32m    115\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdp1(F\u001b[39m.\u001b[39mrelu(y)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/auto/ocr/src/ocr_model.py:36\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m     \u001b[39m# |x| = (batch_size, length, word_vec_size)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x)\n\u001b[1;32m     38\u001b[0m     y \u001b[39m=\u001b[39m x[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:691\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    690\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    692\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    693\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    695\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.17464827793107057\n",
      "test acc:  95.53333333333333\n",
      "saved precision and recall results to file!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       " tensor([0., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.test(test_dataloader=test_dataloader,\n",
    "            device=device, \n",
    "            model=model,\n",
    "            title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded model graph to tensorboard!\n"
     ]
    }
   ],
   "source": [
    "mu.graphModel(train_dataloader, model, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(title, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
