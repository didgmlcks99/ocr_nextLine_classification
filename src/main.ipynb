{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 := delete \\n\n",
    "# 1 := leave as it is\n",
    "\n",
    "# model = gensim.models.Word2Vec.load('../../../pretrained_model/kor/ko.bin')\n",
    "\n",
    "# from hangul_utils import split_syllables, join_jamos\n",
    "# import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import data\n",
    "import bpe\n",
    "import utils\n",
    "import pretrained_model as pm\n",
    "import data_loader as dl\n",
    "import trainer\n",
    "import initializer as init\n",
    "import tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data.getInitData()\n",
    "# data.mk_initData(df)\n",
    "# first_np, second_np, label_np = utils.process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_np, second_np, label_np  = data.getData()\n",
    "first_np, second_np = utils.process_splitted(first_np, second_np)\n",
    "first_ls, second_ls, ch2idx, max_len = utils.tokenize(first_np, second_np)\n",
    "first2idx_np, second2idx_np = utils.encode(first_ls, second_ls, ch2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27 / 132 pretrained vectors found.\n"
     ]
    }
   ],
   "source": [
    "pretrained_word2vec = pm.load_pretrained_model(ch2idx)\n",
    "pretrained_word2vec = torch.tensor(pretrained_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_first, test_first, train_second, test_second, train_labels, test_labels = train_test_split(\n",
    "    first2idx_np, second2idx_np, label_np, test_size = 0.1, random_state = 43\n",
    ")\n",
    "\n",
    "train_first, val_first, train_second, val_second, train_labels, val_labels = train_test_split(\n",
    "    train_first, train_second, train_labels, test_size = 0.1, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = dl.data_loader(train_first,\n",
    "                                                                   train_second,\n",
    "                                                                   val_first,\n",
    "                                                                   val_second,\n",
    "                                                                   test_first,\n",
    "                                                                   test_second,\n",
    "                                                                   train_labels,\n",
    "                                                                   val_labels,\n",
    "                                                                   test_labels,\n",
    "                                                                   batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "# PyTorch TensorBoard support\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('ocr/tests')\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing with pretrained model!!!\n",
      "OCR(\n",
      "  (emb): Embedding(132, 200)\n",
      "  (lstm1): RNN(\n",
      "    (rnn): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (lstm2): RNN(\n",
      "    (rnn): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=400, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "model, optimizer, loss_fn = init.initialize_model(\n",
    "    vocab_size=len(ch2idx),\n",
    "    embed_dim=200,\n",
    "    hidden_size=100,\n",
    "    num_classes=2,\n",
    "    rnn_layers=1,\n",
    "    dropout=0.0,\n",
    "    learning_rate=0.001,\n",
    "    model_name=\"RNN\",\n",
    "    optim_name=\"Adam\",\n",
    "    loss_fn_name=\"CEL\",\n",
    "    pretrained_model=pretrained_word2vec,\n",
    "    freeze_embedding=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   0.239527   | 90.979424  | 0.187160 | 93.33  | 70.99 \n",
      "   2    |   0.152824   | 94.358025  | 0.150207 | 94.81  | 70.17 \n",
      "   3    |   0.131749   | 95.139918  | 0.145590 | 94.37  | 70.48 \n",
      "   4    |   0.119353   | 95.674897  | 0.138006 | 94.89  | 71.33 \n",
      "   5    |   0.109190   | 95.917695  | 0.137656 | 95.04  | 71.48 \n",
      "   6    |   0.103007   | 96.111111  | 0.125594 | 95.63  | 71.63 \n",
      "   7    |   0.096227   | 96.399177  | 0.132787 | 95.00  | 71.85 \n",
      "   8    |   0.089348   | 96.596708  | 0.132698 | 94.78  | 71.56 \n",
      "   9    |   0.082214   | 97.004115  | 0.125319 | 95.26  | 71.93 \n",
      "  10    |   0.076732   | 97.230453  | 0.126546 | 95.19  | 71.92 \n",
      "  11    |   0.070428   | 97.395062  | 0.143881 | 94.78  | 71.06 \n",
      "  12    |   0.066333   | 97.674897  | 0.129552 | 95.19  | 71.02 \n",
      "  13    |   0.059489   | 97.851852  | 0.138091 | 95.19  | 70.70 \n",
      "  14    |   0.054660   | 98.078189  | 0.142680 | 94.93  | 70.26 \n",
      "  15    |   0.047386   | 98.263374  | 0.145770 | 95.59  | 70.08 \n",
      "  16    |   0.041867   | 98.530864  | 0.155224 | 95.00  | 70.74 \n",
      "  17    |   0.040618   | 98.654321  | 0.161561 | 94.85  | 71.27 \n",
      "  18    |   0.033838   | 98.860082  | 0.168415 | 94.89  | 71.67 \n",
      "  19    |   0.027869   | 99.086420  | 0.173696 | 95.26  | 70.95 \n",
      "  20    |   0.027949   | 99.094650  | 0.177323 | 94.67  | 71.21 \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 95.63%.\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    epochs=20,\n",
    "    title='test3',\n",
    "    writer=writer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_pred, tot_label = tester.test(test_dataloader=test_dataloader,\n",
    "                                  device=device, \n",
    "                                  model=model)\n",
    "\n",
    "results = metrics.classification_report(tot_label.cpu(), tot_pred.cpu(), output_dict=True)\n",
    "results_df = pd.DataFrame.from_dict(results).transpose()\n",
    "results_df.to_excel('../result/test3.xlsx', sheet_name='sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, grab a single mini-batch of images\n",
    "dataiter = iter(train_dataloader)\n",
    "first, second, labels = dataiter.next()\n",
    "\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph.\n",
    "writer.add_graph(model.cpu(), (first, second))\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
